{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YunusTamboli/Gen-AI/blob/main/GAI_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Language translation\n"
      ],
      "metadata": {
        "id": "Z6I8z7ieJZOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuGm8SPlJwYr",
        "outputId": "0f3f7218-c0f5-4206-9b43-919054fd0037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (4.67.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]) (5.29.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[sentencepiece]) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[sentencepiece]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[sentencepiece]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[sentencepiece]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[sentencepiece]) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcfeb6c1-380a-4c1d-fba2-161b17de2f36",
        "id": "mis-X9nUJzq8"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the translation pipeline.\n",
        "# This will automatically download a pre-trained model for English to German translation.\n",
        "# The model 'Helsinki-NLP/opus-mt-en-de' is a good choice for this task.\n",
        "translator = pipeline(\"translation_en_to_de\", model=\"Helsinki-NLP/opus-mt-en-de\")\n",
        "\n",
        "print(\"\\n--- English to German Translator ---\")\n",
        "print(\"Enter an English sentence to translate it to German.\")\n",
        "print(\"Type 'quit' to exit.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter your English sentence: \")\n",
        "\n",
        "    if user_input.lower() == 'quit':\n",
        "        print(\"Thank you for using the translator!\")\n",
        "        break\n",
        "\n",
        "    if not user_input:\n",
        "        print(\"Please enter a sentence to translate.\")\n",
        "        continue\n",
        "\n",
        "    # The pipeline handles the translation with a single call.\n",
        "    translation_results = translator(user_input)\n",
        "\n",
        "    # Extract the translated text from the result\n",
        "    translated_text = translation_results[0]['translation_text']\n",
        "\n",
        "    print(\"\\nTranslation Results:\")\n",
        "    print(f\"Original English: {user_input}\")\n",
        "    print(f\"Translated German: {translated_text}\\n\")\n",
        "    print(\"-\" * 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- English to German Translator ---\n",
            "Enter an English sentence to translate it to German.\n",
            "Type 'quit' to exit.\n",
            "------------------------------\n",
            "Enter your English sentence: how are you\n",
            "\n",
            "Translation Results:\n",
            "Original English: how are you\n",
            "Translated German: Wie geht's dir?\n",
            "\n",
            "------------------------------\n",
            "Enter your English sentence: hii  i am suda\n",
            "\n",
            "Translation Results:\n",
            "Original English: hii  i am suda\n",
            "Translated German: hii ich bin suda\n",
            "\n",
            "------------------------------\n",
            "Enter your English sentence: quit\n",
            "Thank you for using the translator!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis using NLTK"
      ],
      "metadata": {
        "id": "VaYBN_EJLi71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Initialize sentiment analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "print(\"\\n--- NLTK Sentiment Analyzer ---\")\n",
        "print(\"Enter a sentence to analyze its sentiment.\")\n",
        "print(\"Type 'quit' to exit.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter a sentence: \")\n",
        "\n",
        "    if user_input.lower() == 'quit':\n",
        "        print(\"Thank you for using the NLTK Sentiment Analyzer!\")\n",
        "        break\n",
        "\n",
        "    if not user_input.strip():\n",
        "        print(\"Please enter some text to analyze.\")\n",
        "        continue\n",
        "\n",
        "    # Perform sentiment analysis\n",
        "    sentiment_scores = sia.polarity_scores(user_input)\n",
        "\n",
        "    # Classify based on compound score\n",
        "    compound_score = sentiment_scores['compound']\n",
        "    if compound_score >= 0.05:\n",
        "        sentiment_class = 'Positive'\n",
        "    elif compound_score <= -0.05:\n",
        "        sentiment_class = 'Negative'\n",
        "    else:\n",
        "        sentiment_class = 'Neutral'\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nAnalysis Results:\")\n",
        "    print(f\"Text: {user_input}\")\n",
        "    print(f\"Negative score: {sentiment_scores['neg']:.2f}\")\n",
        "    print(f\"Neutral score: {sentiment_scores['neu']:.2f}\")\n",
        "    print(f\"Positive score: {sentiment_scores['pos']:.2f}\")\n",
        "    print(f\"Compound score: {compound_score:.2f}\")\n",
        "    print(f\"Overall sentiment: {sentiment_class}\\n\")\n",
        "    print(\"-\" * 30)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRSvA4qZK5e0",
        "outputId": "14cede5a-b8b1-4cde-c667-3bec9b799fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- NLTK Sentiment Analyzer ---\n",
            "Enter a sentence to analyze its sentiment.\n",
            "Type 'quit' to exit.\n",
            "------------------------------\n",
            "Enter a sentence: hi .how are you?\n",
            "\n",
            "Analysis Results:\n",
            "Text: hi .how are you?\n",
            "Negative score: 0.00\n",
            "Neutral score: 1.00\n",
            "Positive score: 0.00\n",
            "Compound score: 0.00\n",
            "Overall sentiment: Neutral\n",
            "\n",
            "------------------------------\n",
            "Enter a sentence: I love learning new things!\n",
            "\n",
            "Analysis Results:\n",
            "Text: I love learning new things!\n",
            "Negative score: 0.00\n",
            "Neutral score: 0.40\n",
            "Positive score: 0.60\n",
            "Compound score: 0.67\n",
            "Overall sentiment: Positive\n",
            "\n",
            "------------------------------\n",
            "Enter a sentence: quit\n",
            "Thank you for using the NLTK Sentiment Analyzer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis using Hugging Face Transformers"
      ],
      "metadata": {
        "id": "eBeNFSTiMGBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install transformers\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the pipeline\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "print(\"\\n--- Hugging Face Sentiment Analysis Pipeline ---\")\n",
        "print(\"Enter a sentence to analyze its sentiment.\")\n",
        "print(\"Type 'quit' to exit.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter your sentence: \")\n",
        "\n",
        "    if user_input.lower() == 'quit':\n",
        "        print(\"Thank you for using the sentiment analysis tool!\")\n",
        "        break\n",
        "\n",
        "    if not user_input.strip():\n",
        "        print(\"Please enter a sentence to analyze.\")\n",
        "        continue\n",
        "\n",
        "    # Process input\n",
        "    results = sentiment_pipeline(user_input)\n",
        "    result = results[0]\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nAnalysis Results:\")\n",
        "    print(f\"Text: {user_input}\")\n",
        "    print(f\"Predicted Label: {result['label']}\")\n",
        "    print(f\"Confidence Score: {result['score']:.4f}\\n\")\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZFKbUnIK5Yv",
        "outputId": "5b8f56a1-e56c-4493-de9f-8174ea1a6a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Hugging Face Sentiment Analysis Pipeline ---\n",
            "Enter a sentence to analyze its sentiment.\n",
            "Type 'quit' to exit.\n",
            "------------------------------\n",
            "Enter your sentence: his is the worst movie I have ever watched.\n",
            "\n",
            "Analysis Results:\n",
            "Text: his is the worst movie I have ever watched.\n",
            "Predicted Label: NEGATIVE\n",
            "Confidence Score: 0.9998\n",
            "\n",
            "------------------------------\n",
            "Enter your sentence: it was good day\n",
            "\n",
            "Analysis Results:\n",
            "Text: it was good day\n",
            "Predicted Label: POSITIVE\n",
            "Confidence Score: 0.9999\n",
            "\n",
            "------------------------------\n",
            "Enter your sentence: quit\n",
            "Thank you for using the sentiment analysis tool!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OR22SxWLK5WW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}